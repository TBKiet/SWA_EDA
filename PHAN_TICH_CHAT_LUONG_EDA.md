| ƒê·∫∑c t√≠nh ch·∫•t l∆∞·ª£ng | L√Ω do quan tr·ªçng | C√¥ng c·ª• h·ªó tr·ª£ | C√°c b∆∞·ªõc ki·ªÉm tra |
|---------------------|------------------|----------------|------------------|
| **Scalability (Kh·∫£ nƒÉng m·ªü r·ªông)** | - X·ª≠ l√Ω t·∫£i l·ªõn t·ª´ nhi·ªÅu ngu·ªìn s·ª± ki·ªán<br>- H·ªó tr·ª£ m·ªü r·ªông ngang d·ªÖ d√†ng<br>- ƒê·∫£m b·∫£o hi·ªáu su·∫•t cao v·ªõi x·ª≠ l√Ω kh√¥ng ƒë·ªìng b·ªô | - **Message Brokers**: Apache Kafka, RabbitMQ, AWS SQS/SNS, Google Pub/Sub, Azure Event Hubs<br>- **Container Orchestration**: Kubernetes, Docker Swarm<br>- **Cloud Services**: AWS Lambda, Google Cloud Functions, Azure Functions<br>- **Monitoring**: Prometheus, Grafana, ELK Stack<br>- **Load Testing**: JMeter, Locust, k6 | 1. X√°c ƒë·ªãnh t·∫£i d·ª± ki·∫øn (s·ªë s·ª± ki·ªán/gi√¢y)<br>2. C·∫•u h√¨nh message broker v√† consumer (Kafka partition, Kubernetes pod)<br>3. M√¥ ph·ªèng t·∫£i l·ªõn b·∫±ng JMeter/Locust<br>4. Gi√°m s√°t ƒë·ªô tr·ªÖ, th√¥ng l∆∞·ª£ng b·∫±ng Prometheus/Grafana<br>5. Th√™m consumer instance ƒë·ªÉ ki·ªÉm tra autoscaling<br>6. ƒê√°nh gi√° hi·ªáu su·∫•t v√† x√°c nh·∫≠n kh√¥ng m·∫•t s·ª± ki·ªán |
| **Reliability (ƒê·ªô tin c·∫≠y)** | - ƒê·∫£m b·∫£o x·ª≠ l√Ω s·ª± ki·ªán √≠t nh·∫•t m·ªôt l·∫ßn ho·∫∑c ch√≠nh x√°c m·ªôt l·∫ßn<br>- X·ª≠ l√Ω l·ªói t·∫°m th·ªùi v√† kh√¥ng kh·∫Øc ph·ª•c ƒë∆∞·ª£c<br>- H·ªó tr·ª£ ph·ª•c h·ªìi sau s·ª± c·ªë | - **Message Brokers**: Kafka (exactly-once), RabbitMQ (ACK/NACK), AWS SQS (DLQ)<br>- **Databases**: DynamoDB, MongoDB, Redis<br>- **Monitoring**: Prometheus, Grafana, AWS CloudWatch, Datadog<br>- **Chaos Engineering**: Chaos Monkey, LitmusChaos<br>- **Retry Libraries**: Spring Retry, Polly | 1. X√°c ƒë·ªãnh y√™u c·∫ßu (at-least-once/exactly-once)<br>2. C·∫•u h√¨nh DLQ, retry v·ªõi exponential backoff, Idempotency Key<br>3. M√¥ ph·ªèng l·ªói (t·∫Øt consumer, ng·∫Øt m·∫°ng)<br>4. Gi√°m s√°t s·ªë l·∫ßn retry, s·ª± ki·ªán th·∫•t b·∫°i b·∫±ng Grafana<br>5. Ki·ªÉm tra ph·ª•c h·ªìi sau khi consumer kh·ªüi ƒë·ªông l·∫°i<br>6. X√°c nh·∫≠n exactly-once delivery qua c∆° s·ªü d·ªØ li·ªáu |
| **Maintainability (Kh·∫£ nƒÉng b·∫£o tr√¨)** | - D·ªÖ s·ª≠a ƒë·ªïi, m·ªü r·ªông h·ªá th·ªëng<br>- H·ªó tr·ª£ ph√°t tri·ªÉn song song<br>- Gi·∫£m r·ªßi ro l·ªói nh·ªù h·ª£p ƒë·ªìng s·ª± ki·ªán r√µ r√†ng | - **Schema Management**: Confluent Schema Registry, JSON Schema, Avro<br>- **Containerization**: Docker, Kubernetes<br>- **CI/CD**: Jenkins, GitHub Actions, GitLab CI<br>- **Code Quality**: SonarQube, ESLint, Checkstyle<br>- **Documentation**: Swagger, OpenAPI, Confluence<br>- **Monitoring**: Prometheus, Grafana | 1. Ki·ªÉm tra loose coupling qua message broker<br>2. ƒê√°nh gi√° single responsibility qua m√£ ngu·ªìn v√† unit test<br>3. Th·ª≠ tri·ªÉn khai ƒë·ªôc l·∫≠p m·ªôt service b·∫±ng Kubernetes<br>4. Ki·ªÉm tra schema s·ª± ki·ªán trong Schema Registry<br>5. Ph√¢n t√≠ch m√£ b·∫±ng SonarQube ƒë·ªÉ t√¨m n·ª£ k·ªπ thu·∫≠t<br>6. Gi√°m s√°t l·ªói runtime v√† hi·ªáu su·∫•t b·∫±ng Grafana |

# Ph√¢n T√≠ch ƒê·∫∑c T√≠nh Ch·∫•t L∆∞·ª£ng Event-Driven Architecture

## Ba ƒê·∫∑c T√≠nh Ch·∫•t L∆∞·ª£ng Mong Mu·ªën Nh·∫•t

### 1. Scalability (Kh·∫£ nƒÉng M·ªü R·ªông)

**T·∫°i sao ƒë√¢y l√† ƒë·∫∑c t√≠nh quan tr·ªçng nh·∫•t:**

- **Horizontal Scaling**: M·ªói microservice c√≥ th·ªÉ scale ƒë·ªôc l·∫≠p theo nhu c·∫ßu c·ª• th·ªÉ
- **Event-driven nature**: Kafka cho ph√©p x·ª≠ l√Ω h√†ng tri·ªáu events/gi√¢y v·ªõi partition scaling
- **Microservice Independence**: C√≥ th·ªÉ th√™m nhi·ªÅu instance c·ªßa m·ªôt service m√† kh√¥ng ·∫£nh h∆∞·ªüng kh√°c
- **Future-proof**: D·ªÖ d√†ng th√™m service m·ªõi v√†o h·ªá sinh th√°i m√† kh√¥ng c·∫ßn ch·ªânh s·ª≠a code hi·ªán c√≥

**Th·ªÉ hi·ªán trong d·ª± √°n:**

```bash
# C√≥ th·ªÉ scale b·∫•t k·ª≥ service n√†o ƒë·ªôc l·∫≠p
docker-compose up --scale user-service=3 --scale notification-service=5
```

**C√°c b∆∞·ªõc t·∫°o ra ƒë·∫∑c t√≠nh Scalability:**

#### B∆∞·ªõc 1: Thi·∫øt k·∫ø Stateless Services
```javascript
// user-service/src/controllers/userController.js
module.exports = {
  createUser: async (request, reply) => {
    // Service kh√¥ng l∆∞u tr·ªØ state, m·ªçi th√¥ng tin ƒë·ªÅu t·ª´ request
    const { username, email, password } = request.body;

    // X·ª≠ l√Ω business logic v√† l∆∞u v√†o database
    const user = await userService.createUser({ username, email, password });

    // Ph√°t event thay v√¨ g·ªçi tr·ª±c ti·∫øp service kh√°c
    await sendUserCreatedEvent(user);

    reply.code(201).send(user);
  }
};
```

#### B∆∞·ªõc 2: C·∫•u h√¨nh Kafka Partitioning
```yaml
# docker-compose.yml - Kafka config cho scaling
kafka:
  environment:
    KAFKA_NUM_PARTITIONS: 3  # Cho ph√©p 3 consumer c√πng x·ª≠ l√Ω
    KAFKA_DEFAULT_REPLICATION_FACTOR: 1
    KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
```

```javascript
// shared/utils/kafkaClient.js - Producer config
const producer = kafka.producer({
  // Partition key ƒë·ªÉ ph√¢n ph·ªëi t·∫£i
  partitioner: Partitioners.LegacyPartitioner
});

await producer.send({
  topic: 'user.created',
  messages: [{
    // S·ª≠ d·ª•ng userId l√†m partition key ƒë·ªÉ ƒë·∫£m b·∫£o order
    key: String(userId),
    value: JSON.stringify(eventData)
  }]
});
```

#### B∆∞·ªõc 3: Container Health Checks cho Auto-scaling
```yaml
# docker-compose.yml
user-service:
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 40s
```

```javascript
// user-service/src/routes/health.js
module.exports = async function (fastify, opts) {
  fastify.get('/health', async (request, reply) => {
    try {
      // Ki·ªÉm tra database connection
      await sequelize.authenticate();

      // Ki·ªÉm tra Kafka connection
      const admin = kafka.admin();
      await admin.listTopics();

      return { status: 'healthy', timestamp: new Date().toISOString() };
    } catch (error) {
      reply.code(503);
      return { status: 'unhealthy', error: error.message };
    }
  });
};
```

#### B∆∞·ªõc 4: Service Discovery cho Dynamic Scaling

**Service Registry Implementation:**

```javascript
// shared/service-discovery/service-registry.js
const Redis = require('redis');

class ServiceRegistry {
  constructor() {
    this.client = Redis.createClient({
      url: process.env.REDIS_URL || 'redis://localhost:6379'
    });
    this.client.connect();
  }

  // ƒêƒÉng k√Ω service khi kh·ªüi ƒë·ªông
  async registerService(serviceName, serviceInfo) {
    const serviceKey = `services:${serviceName}:${serviceInfo.instanceId}`;
    const serviceData = {
      ...serviceInfo,
      registeredAt: new Date().toISOString(),
      lastHeartbeat: new Date().toISOString()
    };

    await this.client.setEx(serviceKey, 30, JSON.stringify(serviceData)); // TTL 30 seconds
    console.log(`‚úÖ Service registered: ${serviceName} at ${serviceInfo.host}:${serviceInfo.port}`);

    // Start heartbeat
    this.startHeartbeat(serviceName, serviceInfo);
  }

  // Heartbeat ƒë·ªÉ duy tr√¨ registration
  startHeartbeat(serviceName, serviceInfo) {
    const heartbeatInterval = setInterval(async () => {
      try {
        const serviceKey = `services:${serviceName}:${serviceInfo.instanceId}`;
        const existingData = await this.client.get(serviceKey);

        if (existingData) {
          const serviceData = JSON.parse(existingData);
          serviceData.lastHeartbeat = new Date().toISOString();
          await this.client.setEx(serviceKey, 30, JSON.stringify(serviceData));
        } else {
          // Re-register if key expired
          await this.registerService(serviceName, serviceInfo);
        }
      } catch (error) {
        console.error('‚ùå Heartbeat failed:', error);
      }
    }, 10000); // Every 10 seconds

    // Cleanup on process termination
    process.on('SIGTERM', () => {
      clearInterval(heartbeatInterval);
      this.deregisterService(serviceName, serviceInfo.instanceId);
    });
  }

  // T√¨m t·∫•t c·∫£ instances c·ªßa m·ªôt service
  async discoverService(serviceName) {
    const pattern = `services:${serviceName}:*`;
    const keys = await this.client.keys(pattern);

    const services = [];
    for (const key of keys) {
      const serviceData = await this.client.get(key);
      if (serviceData) {
        services.push(JSON.parse(serviceData));
      }
    }

    return services.filter(service => {
      // Filter out stale services (no heartbeat for 60 seconds)
      const lastHeartbeat = new Date(service.lastHeartbeat);
      const now = new Date();
      return (now - lastHeartbeat) < 60000;
    });
  }

  // Load balancer - ch·ªçn service instance
  async getServiceInstance(serviceName, strategy = 'round-robin') {
    const instances = await this.discoverService(serviceName);

    if (instances.length === 0) {
      throw new Error(`No healthy instances found for service: ${serviceName}`);
    }

    switch (strategy) {
      case 'round-robin':
        return this.roundRobinSelection(serviceName, instances);
      case 'random':
        return instances[Math.floor(Math.random() * instances.length)];
      case 'least-connections':
        return this.leastConnectionsSelection(instances);
      default:
        return instances[0];
    }
  }

  roundRobinSelection(serviceName, instances) {
    const counterKey = `lb:${serviceName}:counter`;
    return this.client.incr(counterKey).then(counter => {
      return instances[(counter - 1) % instances.length];
    });
  }

  leastConnectionsSelection(instances) {
    // Simplified: ch·ªçn instance v·ªõi √≠t connection nh·∫•t
    return instances.reduce((least, current) =>
      (current.connections || 0) < (least.connections || 0) ? current : least
    );
  }

  async deregisterService(serviceName, instanceId) {
    const serviceKey = `services:${serviceName}:${instanceId}`;
    await this.client.del(serviceKey);
    console.log(`üóëÔ∏è Service deregistered: ${serviceName}:${instanceId}`);
  }
}

module.exports = ServiceRegistry;
```

**Service Registration trong t·ª´ng service:**

```javascript
// user-service/src/index.js
const ServiceRegistry = require('../shared/service-discovery/service-registry');
const { v4: uuidv4 } = require('uuid');

const serviceRegistry = new ServiceRegistry();
const instanceId = uuidv4();

const start = async () => {
  try {
    await fastify.register(app);

    const port = process.env.PORT || 3001;
    const host = process.env.HOST || '0.0.0.0';

    await fastify.listen({ port, host });

    // ƒêƒÉng k√Ω service v·ªõi service discovery
    await serviceRegistry.registerService('user-service', {
      instanceId,
      host: process.env.PUBLIC_HOST || 'user-service',
      port,
      version: '1.0.0',
      metadata: {
        capabilities: ['user-management', 'authentication'],
        region: process.env.REGION || 'default'
      }
    });

    fastify.log.info(`User Service running on port ${port}`);
  } catch (err) {
    fastify.log.error(err);
    process.exit(1);
  }
};

start();
```

**Dynamic Service Discovery trong Gateway:**

```javascript
// gateway/src/services/service-discovery-client.js
const ServiceRegistry = require('../../shared/service-discovery/service-registry');

class ServiceDiscoveryClient {
  constructor() {
    this.serviceRegistry = new ServiceRegistry();
    this.serviceCache = new Map();
    this.cacheExpiry = new Map();
  }

  async getServiceUrl(serviceName) {
    // Check cache first
    if (this.isServiceCached(serviceName)) {
      return this.serviceCache.get(serviceName);
    }

    // Discover service instance
    const instance = await this.serviceRegistry.getServiceInstance(serviceName);
    const serviceUrl = `http://${instance.host}:${instance.port}`;

    // Cache for 30 seconds
    this.serviceCache.set(serviceName, serviceUrl);
    this.cacheExpiry.set(serviceName, Date.now() + 30000);

    return serviceUrl;
  }

  isServiceCached(serviceName) {
    const expiry = this.cacheExpiry.get(serviceName);
    if (expiry && Date.now() < expiry) {
      return true;
    }

    // Cleanup expired cache
    this.serviceCache.delete(serviceName);
    this.cacheExpiry.delete(serviceName);
    return false;
  }

  // Circuit breaker pattern
  async callService(serviceName, path, options = {}) {
    const maxRetries = 3;
    let lastError;

    for (let retry = 0; retry < maxRetries; retry++) {
      try {
        const serviceUrl = await this.getServiceUrl(serviceName);
        const response = await fetch(`${serviceUrl}${path}`, options);

        if (!response.ok) {
          throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }

        return response;
      } catch (error) {
        lastError = error;
        console.warn(`‚ö†Ô∏è Service call failed (attempt ${retry + 1}):`, error.message);

        // Invalidate cache on error
        this.serviceCache.delete(serviceName);
        this.cacheExpiry.delete(serviceName);

        // Exponential backoff
        if (retry < maxRetries - 1) {
          await new Promise(resolve => setTimeout(resolve, Math.pow(2, retry) * 1000));
        }
      }
    }

    throw new Error(`Service ${serviceName} unavailable after ${maxRetries} retries: ${lastError.message}`);
  }
}

module.exports = ServiceDiscoveryClient;
```

**Gateway s·ª≠ d·ª•ng Service Discovery:**

```javascript
// gateway/src/routes/users.js
const ServiceDiscoveryClient = require('../services/service-discovery-client');

module.exports = async function (fastify, opts) {
  const serviceDiscovery = new ServiceDiscoveryClient();

  fastify.post('/users', async (request, reply) => {
    try {
      // Dynamic service discovery thay v√¨ hardcode URL
      const response = await serviceDiscovery.callService('user-service', '/users', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(request.body)
      });

      const userData = await response.json();
      return userData;
    } catch (error) {
      reply.code(503);
      return {
        error: 'User service unavailable',
        message: error.message,
        timestamp: new Date().toISOString()
      };
    }
  });

  fastify.post('/registrations', async (request, reply) => {
    try {
      const response = await serviceDiscovery.callService('registration-service', '/registrations', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(request.body)
      });

      const registrationData = await response.json();
      return registrationData;
    } catch (error) {
      reply.code(503);
      return { error: 'Registration service unavailable', message: error.message };
    }
  });
};
```

**Docker Compose v·ªõi Service Discovery:**

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Service Discovery Registry
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - eventflow-network

  # Gateway v·ªõi service discovery
  gateway:
    build: ./gateway
    environment:
      - REDIS_URL=redis://redis:6379
      - PUBLIC_HOST=gateway
    depends_on:
      - redis
      - kafka
    ports:
      - "3007:3000"
    networks:
      - eventflow-network

  # User service instances (c√≥ th·ªÉ scale)
  user-service:
    build: ./user-service
    environment:
      - REDIS_URL=redis://redis:6379
      - PUBLIC_HOST=user-service
      - DATABASE_URL=postgres://postgres:admin@postgres:5432/userdb
      - KAFKA_BROKERS=kafka:9092
    depends_on:
      - redis
      - postgres
      - kafka
    # Kh√¥ng expose port c·ªë ƒë·ªãnh, ƒë·ªÉ auto-assign
    networks:
      - eventflow-network

  # Registration service instances
  registration-service:
    build: ./registration-service
    environment:
      - REDIS_URL=redis://redis:6379
      - PUBLIC_HOST=registration-service
      - DATABASE_URL=postgres://postgres:admin@postgres:5432/registrationdb
      - KAFKA_BROKERS=kafka:9092
    depends_on:
      - redis
      - postgres
      - kafka
    networks:
      - eventflow-network

volumes:
  redis-data:

networks:
  eventflow-network:
    driver: bridge
```

**Scaling v·ªõi Service Discovery:**

```bash
# Scale services dynamically
docker-compose up --scale user-service=5 --scale registration-service=3

# Gateway s·∫Ω t·ª± ƒë·ªông ph√°t hi·ªán v√† load balance gi·ªØa c√°c instances
# Redis s·∫Ω track t·∫•t c·∫£ service instances v√† health status
```

### 2. Reliability (ƒê·ªô Tin C·∫≠y)

**T·∫°i sao quan tr·ªçng:**

- **Message Durability**: Kafka ƒë·∫£m b·∫£o events kh√¥ng b·ªã m·∫•t v·ªõi persistent storage
- **At-least-once delivery**: M·ªói event ƒë∆∞·ª£c ƒë·∫£m b·∫£o x·ª≠ l√Ω √≠t nh·∫•t 1 l·∫ßn
- **Fault Isolation**: L·ªói ·ªü m·ªôt service kh√¥ng l√†m crash to√†n b·ªô h·ªá th·ªëng
- **Retry Mechanisms**: Consumer c√≥ th·ªÉ retry khi x·ª≠ l√Ω th·∫•t b·∫°i

**Th·ªÉ hi·ªán trong d·ª± √°n:**

```javascript
// Audit service ƒë·∫£m b·∫£o m·ªçi event ƒë·ªÅu ƒë∆∞·ª£c ghi l·∫°i
await logAudit({
  eventType: EVENT_TOPICS.USER_CREATED,
  data: { userId, username, userEmail, timestamp },
});
```

**C√°c b∆∞·ªõc t·∫°o ra ƒë·∫∑c t√≠nh Reliability:**

#### B∆∞·ªõc 1: C·∫•u h√¨nh Kafka Message Durability
```yaml
# docker-compose.yml - Kafka persistence config
kafka:
  environment:
    KAFKA_LOG_RETENTION_HOURS: 168  # 7 days retention
    KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1GB per partition
    KAFKA_LOG_SEGMENT_BYTES: 1073741824
    KAFKA_FLUSH_MESSAGES: 1000  # Flush every 1000 messages
```

#### B∆∞·ªõc 2: Implement Consumer Retry Logic
```javascript
// auditlog-service/src/consumers/userCreated.js
module.exports = async () => {
  const consumer = await createConsumer('audit-user-created');

  await consumer.run({
    eachMessage: async ({ topic, partition, message }) => {
      let retries = 0;
      const maxRetries = 3;

      while (retries < maxRetries) {
        try {
          const data = JSON.parse(message.value?.toString() || '{}');

          // Validate required fields
          if (!data.userId) {
            console.warn('‚ö†Ô∏è Missing userId in message:', data);
            return; // Skip invalid messages
          }

          // Trigger audit logging v·ªõi idempotency check
          await logAuditWithRetry(data);
          console.log(`‚úÖ Audit log created for ${topic}`);
          break; // Success, exit retry loop

        } catch (error) {
          retries++;
          console.error(`‚ùå Attempt ${retries} failed:`, error.message);

          if (retries >= maxRetries) {
            // Send to Dead Letter Queue after max retries
            await sendToDeadLetterQueue(topic, message, error);
            console.error(`üíÄ Message sent to DLQ after ${maxRetries} retries`);
          } else {
            // Exponential backoff delay
            const delay = Math.pow(2, retries) * 1000;
            await new Promise(resolve => setTimeout(resolve, delay));
          }
        }
      }
    },
  });
};

async function logAuditWithRetry(data) {
  // Idempotent check - avoid duplicate logs
  const existingLog = await AuditLog.findOne({
    where: {
      eventType: data.eventType,
      'data.userId': data.userId,
      'data.timestamp': data.timestamp
    }
  });

  if (existingLog) {
    console.log('‚ö†Ô∏è Audit log already exists, skipping');
    return existingLog;
  }

  return await logAudit(data);
}
```

#### B∆∞·ªõc 3: Circuit Breaker Pattern cho External Services
```javascript
// notification-service/src/services/emailService.js
const CircuitBreaker = require('opossum');

const emailOptions = {
  timeout: 10000, // 10 seconds
  errorThresholdPercentage: 50, // Open circuit if 50% of requests fail
  resetTimeout: 30000, // Try again after 30 seconds
  rollingCountTimeout: 60000, // 1 minute window
  rollingCountBuckets: 6
};

const emailCircuitBreaker = new CircuitBreaker(sendEmailInternal, emailOptions);

// Fallback when circuit is open
emailCircuitBreaker.fallback(() => {
  console.log('‚ö° Email service circuit breaker is open, using fallback');
  // Log to queue for later retry
  return { success: false, reason: 'circuit_breaker_open' };
});

async function sendEmail(to, subject, body) {
  try {
    return await emailCircuitBreaker.fire(to, subject, body);
  } catch (error) {
    // Even if email fails, system continues to work
    console.error('üìß Email service unavailable:', error.message);
    return { success: false, error: error.message };
  }
}
```

#### B∆∞·ªõc 4: Database Transaction v·ªõi Event Publishing
```javascript
// user-service/src/services/userService.js - Transactional Outbox Pattern
async function createUser(userData) {
  const transaction = await sequelize.transaction();

  try {
    // 1. Save user to database
    const user = await User.create(userData, { transaction });

    // 2. Save event to outbox table (same transaction)
    const eventData = {
      userId: user.id,
      username: user.username,
      userEmail: user.email,
      timestamp: new Date().toISOString()
    };

    await OutboxEvent.create({
      eventType: 'user.created',
      aggregateId: user.id,
      eventData: JSON.stringify(eventData),
      processed: false
    }, { transaction });

    // 3. Commit transaction
    await transaction.commit();

    // 4. Publish event after successful commit
    await publishUserCreatedEvent(eventData);

    return user;
  } catch (error) {
    await transaction.rollback();
    throw error;
  }
}

// Background process to handle failed event publishing
setInterval(async () => {
  const unprocessedEvents = await OutboxEvent.findAll({
    where: { processed: false },
    limit: 100
  });

  for (const event of unprocessedEvents) {
    try {
      await publishEvent(event.eventType, JSON.parse(event.eventData));
      event.processed = true;
      await event.save();
    } catch (error) {
      console.error('Failed to publish outbox event:', error);
    }
  }
}, 30000); // Every 30 seconds
```

### 3. Maintainability (Kh·∫£ nƒÉng B·∫£o Tr√¨)

**T·∫°i sao quan tr·ªçng:**

- **Loose Coupling**: Services ch·ªâ bi·∫øt v·ªÅ events, kh√¥ng bi·∫øt v·ªÅ nhau
- **Single Responsibility**: M·ªói service c√≥ m·ªôt tr√°ch nhi·ªám r√µ r√†ng
- **Independent Deployment**: Deploy t·ª´ng service ri√™ng bi·ªát kh√¥ng ·∫£nh h∆∞·ªüng kh√°c
- **Clear Event Contracts**: Event schema r√µ r√†ng, d·ªÖ hi·ªÉu v√† maintain

**Th·ªÉ hi·ªán trong d·ª± √°n:**

```javascript
// M·ªói service ch·ªâ c·∫ßn bi·∫øt v·ªÅ event schema
{
  "eventType": "registration.created",
  "data": {
    "userId": 123,
    "eventId": "uuid-456",
    "userEmail": "user@example.com"
  }
}
```

**C√°c b∆∞·ªõc t·∫°o ra ƒë·∫∑c t√≠nh Maintainability:**

#### B∆∞·ªõc 1: Implement Loose Coupling qua Event-Driven Communication
```javascript
// ‚ùå TIGHT COUPLING - C√°ch c≈© (kh√¥ng t·ªët)
// user-service/src/controllers/userController.js
async createUser(userData) {
  const user = await userService.createUser(userData);

  // Direct HTTP calls t·∫°o tight coupling
  await axios.post('http://notification-service:3004/send-welcome-email', {
    userId: user.id,
    email: user.email
  });

  await axios.post('http://audit-service:3005/log-action', {
    action: 'user_created',
    userId: user.id
  });

  return user;
}

// ‚úÖ LOOSE COUPLING - C√°ch m·ªõi (Event-Driven)
// user-service/src/controllers/userController.js
async createUser(userData) {
  const user = await userService.createUser(userData);

  // Ch·ªâ ph√°t event, kh√¥ng bi·∫øt ai s·∫Ω x·ª≠ l√Ω
  await sendUserCreatedEvent({
    userId: user.id,
    username: user.username,
    userEmail: user.email,
    timestamp: new Date().toISOString()
  });

  return user; // Service kh√¥ng ph·ª• thu·ªôc v√†o consumer
}
```

#### B∆∞·ªõc 2: Centralized Event Types Definition
```javascript
// shared/event-types.js - Single source of truth cho events
module.exports = {
  EVENT_TOPICS: {
    // User domain events
    USER_CREATED: 'user.created',
    USER_LOGGED_IN: 'user.logged_in',
    USER_UPDATED: 'user.updated',

    // Registration domain events
    REGISTRATION_CREATED: 'registration.created',
    REGISTRATION_CANCELLED: 'registration.cancelled',

    // Notification domain events
    NOTIFICATION_SENT: 'notification.sent',
    NOTIFICATION_FAILED: 'notification.failed',

    // Audit domain events
    AUDIT_LOGGED: 'audit.logged',
    AUDIT_FAILED: 'audit.failed',
  },
};

// shared/schema/userEvents.js - Event schema validation
const Joi = require('joi');

const UserCreatedSchema = Joi.object({
  userId: Joi.number().integer().positive().required(),
  username: Joi.string().min(3).max(50).required(),
  userEmail: Joi.string().email().required(),
  timestamp: Joi.string().isoDate().required(),
  version: Joi.number().integer().default(1) // Schema versioning
});

module.exports = { UserCreatedSchema };
```

#### B∆∞·ªõc 3: Service Independence v·ªõi Separate Databases
```javascript
// user-service/src/models/user.js - Own database
const { Sequelize, DataTypes } = require('sequelize');
const sequelize = new Sequelize(process.env.USER_DATABASE_URL);

const User = sequelize.define('User', {
  id: { type: DataTypes.INTEGER, primaryKey: true, autoIncrement: true },
  username: { type: DataTypes.STRING, unique: true, allowNull: false },
  email: { type: DataTypes.STRING, unique: true, allowNull: false },
  password: { type: DataTypes.STRING, allowNull: false }
});

// event-service/src/models/event.js - Own database
const sequelize = new Sequelize(process.env.EVENT_DATABASE_URL);

const Event = sequelize.define('Event', {
  id: { type: DataTypes.UUID, primaryKey: true, defaultValue: DataTypes.UUIDV4 },
  name: { type: DataTypes.STRING, allowNull: false },
  capacity: { type: DataTypes.INTEGER, allowNull: false },
  registered: { type: DataTypes.INTEGER, defaultValue: 0 }
});

// auditlog-service/src/models/auditLog.js - Own MongoDB database
const mongoose = require('mongoose');

const auditLogSchema = new mongoose.Schema({
  eventType: { type: String, required: true },
  data: { type: mongoose.Schema.Types.Mixed, required: true },
  timestamp: { type: Date, default: Date.now },
  serviceSource: { type: String, required: true }
});

const AuditLog = mongoose.model('AuditLog', auditLogSchema);
```

#### B∆∞·ªõc 4: Consumer-Driven Contract Testing
```javascript
// notification-service/src/consumers/registrationCreated.js
// Consumer ch·ªâ c·∫ßn bi·∫øt v·ªÅ event contract, kh√¥ng bi·∫øt v·ªÅ producer
const { createConsumer } = require('../../shared/utils/kafkaClient');
const { EVENT_TOPICS } = require('../../shared/event-types');

module.exports = async () => {
  const consumer = await createConsumer('notification-group');

  await consumer.subscribe({
    topic: EVENT_TOPICS.REGISTRATION_CREATED,
    fromBeginning: true,
  });

  await consumer.run({
    eachMessage: async ({ message }) => {
      try {
        const eventData = JSON.parse(message.value?.toString() || '{}');

        // Contract validation - consumer defines what it needs
        const requiredFields = ['eventId', 'userId', 'userEmail'];
        for (const field of requiredFields) {
          if (!eventData[field]) {
            console.warn(`‚ö†Ô∏è Missing required field: ${field}`);
            return; // Skip processing
          }
        }

        // Consumer c√≥ th·ªÉ x·ª≠ l√Ω ƒë·ªôc l·∫≠p
        await sendRegistrationConfirmationEmail(eventData);

      } catch (error) {
        console.error('‚ùå Error processing registration event:', error);
      }
    },
  });
};

// Consumer kh√¥ng c·∫ßn bi·∫øt producer l√† g√¨, ch·ªâ c·∫ßn event format
async function sendRegistrationConfirmationEmail({ eventId, userId, userEmail }) {
  // Fetch additional data if needed (loose coupling)
  const eventDetails = await fetchEventDetails(eventId);

  const emailContent = {
    to: userEmail,
    subject: `Registration Confirmed: ${eventDetails.name}`,
    body: `Your registration for ${eventDetails.name} has been confirmed.`
  };

  await sendEmail(emailContent);
}
```

#### B∆∞·ªõc 5: API Gateway Pattern cho Service Abstraction
```javascript
// gateway/src/routes/users.js - Single entry point
module.exports = async function (fastify, opts) {
  // Gateway routes requests, but services remain decoupled
  fastify.post('/users', async (request, reply) => {
    try {
      // Forward to user-service
      const response = await fastify.httpClient.post(
        'http://user-service:3001/users',
        request.body
      );

      return response.data;
    } catch (error) {
      reply.code(error.response?.status || 500);
      return { error: error.message };
    }
  });

  fastify.post('/registrations', async (request, reply) => {
    try {
      // Forward to registration-service
      const response = await fastify.httpClient.post(
        'http://registration-service:3003/registrations',
        request.body
      );

      return response.data;
    } catch (error) {
      reply.code(error.response?.status || 500);
      return { error: error.message };
    }
  });
};

// Services don't know about each other, only about events
// Gateway provides unified interface but services stay decoupled
```

#### B∆∞·ªõc 6: Independent Deployment Configuration
```yaml
# docker-compose.yml - Each service can be deployed independently
version: '3.8'
services:
  user-service:
    build: ./user-service
    environment:
      - DATABASE_URL=postgres://postgres:admin@postgres:5432/userdb
      - KAFKA_BROKERS=kafka:9092
    depends_on:
      - postgres
      - kafka
    # Can be scaled independently

  notification-service:
    build: ./notification-service
    environment:
      - KAFKA_BROKERS=kafka:9092
      - SMTP_HOST=${SMTP_HOST}
    depends_on:
      - kafka
    # No database dependency - truly independent

  auditlog-service:
    build: ./auditlog-service
    environment:
      - MONGODB_URI=mongodb://mongo:27017/auditdb
      - KAFKA_BROKERS=kafka:9092
    depends_on:
      - mongo
      - kafka
    # Different database technology - independent choice
```

---

## So S√°nh: Tight Coupling vs Loose Coupling

### ‚ùå Tight Coupling (C√°ch c≈© - Monolithic)

```javascript
// T·∫•t c·∫£ logic trong 1 service - tight coupling
class UserController {
  async createUser(userData) {
    // 1. T·∫°o user
    const user = await this.userService.create(userData);

    // 2. G·ª≠i email tr·ª±c ti·∫øp - tight coupling v·ªõi email service
    await this.emailService.sendWelcomeEmail(user.email, user.name);

    // 3. Log audit tr·ª±c ti·∫øp - tight coupling v·ªõi audit service
    await this.auditService.log('USER_CREATED', user.id);

    // 4. C·∫≠p nh·∫≠t th·ªëng k√™ - tight coupling v·ªõi stats service
    await this.statsService.incrementUserCount();

    return user;
  }
}

// V·∫•n ƒë·ªÅ c·ªßa c√°ch n√†y:
// - N·∫øu email service down ‚Üí to√†n b·ªô t·∫°o user th·∫•t b·∫°i
// - Th√™m service m·ªõi ‚Üí ph·∫£i s·ª≠a code UserController
// - Kh√≥ test, kh√≥ scale, kh√≥ maintain
```

### ‚úÖ Loose Coupling (Event-Driven Architecture)

```javascript
// user-service: Ch·ªâ lo t·∫°o user v√† ph√°t event
class UserController {
  async createUser(userData) {
    // 1. T·∫°o user - single responsibility
    const user = await this.userService.create(userData);

    // 2. Ph√°t event - kh√¥ng bi·∫øt ai s·∫Ω x·ª≠ l√Ω
    await this.eventPublisher.publish('user.created', {
      userId: user.id,
      username: user.username,
      userEmail: user.email,
      timestamp: new Date().toISOString()
    });

    return user; // Xong vi·ªác, kh√¥ng c·∫ßn bi·∫øt g√¨ kh√°c
  }
}

// notification-service: Consumer ƒë·ªôc l·∫≠p
class NotificationConsumer {
  async handleUserCreated(event) {
    // Ch·ªâ quan t√¢m ƒë·∫øn event data, kh√¥ng bi·∫øt producer
    await this.emailService.sendWelcomeEmail(
      event.userEmail,
      event.username
    );
  }
}

// auditlog-service: Consumer ƒë·ªôc l·∫≠p kh√°c
class AuditConsumer {
  async handleUserCreated(event) {
    await this.auditRepo.log({
      eventType: 'USER_CREATED',
      userId: event.userId,
      timestamp: event.timestamp
    });
  }
}

// L·ª£i √≠ch:
// - Email service down ‚Üí user v·∫´n t·∫°o ƒë∆∞·ª£c
// - Th√™m service m·ªõi ‚Üí ch·ªâ c·∫ßn listen event, kh√¥ng s·ª≠a code c≈©
// - D·ªÖ test t·ª´ng ph·∫ßn ri√™ng bi·ªát
// - Scale ƒë·ªôc l·∫≠p t·ª´ng service
```

## C√¥ng C·ª• v√† B∆∞·ªõc Ki·ªÉm Tra Ch·∫•t L∆∞·ª£ng

### 1. Ki·ªÉm tra Scalability

**C√¥ng c·ª•:**

- **K6**: Load testing tool
- **Apache JMeter**: Performance testing
- **Kafka Consumer Lag Monitoring**: Theo d√µi throughput
- **Docker Compose Scaling**: Horizontal scaling test

**B∆∞·ªõc th·ª±c hi·ªán:**

#### B∆∞·ªõc 1: C√†i ƒë·∫∑t K6 v√† t·∫°o test script

```bash
# C√†i ƒë·∫∑t K6
npm install -g k6

# T·∫°o file test scalability
cat > scalability-test.js << 'EOF'
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 100 }, // Ramp up to 100 users
    { duration: '5m', target: 100 }, // Stay at 100 users
    { duration: '2m', target: 200 }, // Ramp up to 200 users
    { duration: '5m', target: 200 }, // Stay at 200 users
    { duration: '2m', target: 0 },   // Ramp down to 0 users
  ],
};

export default function() {
  // Test user creation
  let userPayload = JSON.stringify({
    username: `testuser_${Math.random()}`,
    email: `test_${Math.random()}@example.com`,
    password: 'password123'
  });

  let userResponse = http.post('http://localhost:3007/users', userPayload, {
    headers: { 'Content-Type': 'application/json' },
  });

  check(userResponse, {
    'user creation status is 201': (r) => r.status === 201,
    'user creation response time < 500ms': (r) => r.timings.duration < 500,
  });

  sleep(1);

  // Test event registration if user created successfully
  if (userResponse.status === 201) {
    let regPayload = JSON.stringify({
      eventId: '123e4567-e89b-12d3-a456-426614174000',
      userId: JSON.parse(userResponse.body).id,
      userEmail: JSON.parse(userResponse.body).email
    });

    let regResponse = http.post('http://localhost:3007/registrations', regPayload, {
      headers: { 'Content-Type': 'application/json' },
    });

    check(regResponse, {
      'registration status is 201': (r) => r.status === 201,
      'registration response time < 300ms': (r) => r.timings.duration < 300,
    });
  }
}
EOF
```

#### B∆∞·ªõc 2: Ch·∫°y test v√† scale services

```bash
# Ch·∫°y test
k6 run scalability-test.js

# Scale services trong khi test ƒëang ch·∫°y
docker-compose up --scale user-service=3 --scale registration-service=2

# Monitoring Kafka consumer lag
docker exec kafka kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups
```

#### B∆∞·ªõc 3: Monitoring throughput code

```javascript
// monitoring/throughput-monitor.js
const { kafka } = require('../shared/utils/kafkaClient');

async function monitorConsumerLag() {
  const admin = kafka.admin();

  try {
    await admin.connect();

    // Get consumer groups
    const groups = await admin.listGroups();

    for (const group of groups.groups) {
      const groupDescription = await admin.describeGroups([group.groupId]);
      console.log(`Consumer Group: ${group.groupId}`);

      // Get group offsets
      const offsets = await admin.fetchOffsets({
        groupId: group.groupId,
        topics: ['user.created', 'registration.created', 'notification.sent']
      });

      console.log('Current offsets:', offsets);

      // Calculate lag (simplified)
      for (const topicOffset of offsets) {
        console.log(`Topic: ${topicOffset.topic}`);
        for (const partitionOffset of topicOffset.partitions) {
          console.log(`Partition ${partitionOffset.partition}: Offset ${partitionOffset.offset}`);
        }
      }
    }
  } finally {
    await admin.disconnect();
  }
}

// Run every 10 seconds
setInterval(monitorConsumerLag, 10000);
```

### 2. Ki·ªÉm tra Reliability

**C√¥ng c·ª•:**

- **Chaos Engineering**: Chaos Monkey simulation
- **Message Verification**: Ki·ªÉm tra message persistence
- **Dead Letter Queue Testing**: Test error handling
- **Health Check Monitoring**: Service availability

**B∆∞·ªõc th·ª±c hi·ªán:**

#### B∆∞·ªõc 1: T·∫°o script Chaos Testing

```bash
# T·∫°o script Chaos Testing
cat > chaos-test.sh << 'EOF'
#!/bin/bash

echo "Starting Chaos Engineering Test..."

# Kill random service
SERVICES=("user-service" "event-service" "registration-service" "notification-service" "auditlog-service")
RANDOM_SERVICE=${SERVICES[$RANDOM % ${#SERVICES[@]}]}

echo "Killing service: $RANDOM_SERVICE"
docker-compose kill $RANDOM_SERVICE

# Wait and observe
echo "Waiting 30 seconds to observe system behavior..."
sleep 30

# Check if other services still working
echo "Checking remaining services health..."
curl -f http://localhost:3007/health || echo "Gateway down"
curl -f http://localhost:3001/health || echo "User service down"
curl -f http://localhost:3002/health || echo "Event service down"

# Restart the killed service
echo "Restarting $RANDOM_SERVICE"
docker-compose up -d $RANDOM_SERVICE

echo "Chaos test completed"
EOF

chmod +x chaos-test.sh
./chaos-test.sh
```

#### B∆∞·ªõc 2: Test Message Persistence

```javascript
// test-message-persistence.js
const { kafka } = require('./shared/utils/kafkaClient');

async function testMessagePersistence() {
  const producer = kafka.producer();
  const consumer = kafka.consumer({ groupId: 'test-persistence' });

  try {
    await producer.connect();
    await consumer.connect();

    // Send test message
    const testMessage = {
      userId: 999,
      eventId: 'test-event',
      timestamp: new Date().toISOString()
    };

    await producer.send({
      topic: 'registration.created',
      messages: [{ value: JSON.stringify(testMessage) }]
    });

    console.log('Message sent');

    // Verify message still exists
    await consumer.subscribe({ topic: 'registration.created', fromBeginning: true });

    let messageFound = false;
    await consumer.run({
      eachMessage: async ({ message }) => {
        const data = JSON.parse(message.value.toString());
        if (data.userId === 999) {
          messageFound = true;
          console.log('Message persisted successfully:', data);
        }
      }
    });

    setTimeout(() => {
      if (messageFound) {
        console.log('Reliability test PASSED');
      } else {
        console.log('Reliability test FAILED');
      }
      process.exit(0);
    }, 5000);

  } catch (error) {
    console.error('Error in persistence test:', error);
  }
}

testMessagePersistence();
```

#### B∆∞·ªõc 3: Test Idempotency

```javascript
// reliability/idempotency-test.js
const axios = require('axios');

async function testIdempotency() {
  console.log('Testing Idempotency...');

  // Create user multiple times with same data
  const userData = {
    username: 'idempotency-test-user',
    email: 'idempotency@test.com',
    password: 'password123'
  };

  const requests = [];
  for (let i = 0; i < 5; i++) {
    requests.push(
      axios.post('http://localhost:3007/users', userData)
        .catch(error => error.response)
    );
  }

  const responses = await Promise.all(requests);

  // First should succeed, others should fail gracefully
  const successCount = responses.filter(r => r.status === 201).length;
  const duplicateCount = responses.filter(r => r.status === 400 &&
    r.data.error.includes('already exists')).length;

  console.log(`Success responses: ${successCount}`);
  console.log(`Duplicate responses: ${duplicateCount}`);

  if (successCount === 1 && duplicateCount === 4) {
    console.log('Idempotency test PASSED');
  } else {
    console.log('Idempotency test FAILED');
  }
}

testIdempotency();
```

### 3. Ki·ªÉm tra Maintainability

**C√¥ng c·ª•:**

- **ESLint**: Code quality analysis
- **Dependency Graph Analysis**: Service coupling analysis
- **API Contract Testing**: Event schema validation
- **Documentation Coverage**: API documentation completeness

**B∆∞·ªõc th·ª±c hi·ªán:**

#### B∆∞·ªõc 1: Code Quality Analysis

```bash
# T·∫°o ESLint config
cat > .eslintrc.js << 'EOF'
module.exports = {
  env: {
    commonjs: true,
    es2021: true,
    node: true,
  },
  extends: ['eslint:recommended'],
  parserOptions: {
    ecmaVersion: 12,
  },
  rules: {
    'complexity': ['warn', 10],
    'max-depth': ['warn', 3],
    'max-lines-per-function': ['warn', 50],
    'no-console': 'off',
  },
};
EOF

# Run ESLint on all services
for service in user-service event-service registration-service notification-service auditlog-service gateway; do
  echo "Analyzing $service..."
  npx eslint $service/src --ext .js
done
```

#### B∆∞·ªõc 2: Service Coupling Analysis

```javascript
// analyze-coupling.js
const fs = require('fs');
const path = require('path');

function analyzeCoupling() {
  const services = ['user-service', 'event-service', 'registration-service', 'notification-service', 'auditlog-service', 'gateway'];
  const coupling = {};

  services.forEach(service => {
    coupling[service] = {
      directCalls: [],
      eventDependencies: [],
      sharedModules: []
    };

    // Analyze source files
    const srcDir = path.join(service, 'src');
    if (fs.existsSync(srcDir)) {
      scanDirectory(srcDir, service, coupling);
    }
  });

  console.log('Service Coupling Analysis:');
  console.log(JSON.stringify(coupling, null, 2));

  // Calculate coupling metrics
  let totalDirectCalls = 0;
  let totalEventCalls = 0;

  Object.values(coupling).forEach(serviceData => {
    totalDirectCalls += serviceData.directCalls.length;
    totalEventCalls += serviceData.eventDependencies.length;
  });

  console.log(`\nMetrics:`);
  console.log(`Direct service calls: ${totalDirectCalls}`);
  console.log(`Event-based communications: ${totalEventCalls}`);
  console.log(`Coupling ratio: ${totalDirectCalls/(totalDirectCalls + totalEventCalls)}`);
}

function scanDirectory(dir, service, coupling) {
  const files = fs.readdirSync(dir);

  files.forEach(file => {
    const filePath = path.join(dir, file);
    const stat = fs.statSync(filePath);

    if (stat.isDirectory()) {
      scanDirectory(filePath, service, coupling);
    } else if (file.endsWith('.js')) {
      const content = fs.readFileSync(filePath, 'utf8');

      // Look for direct HTTP calls to other services
      const httpCallMatches = content.match(/http:\/\/[\w-]+:\d+/g);
      if (httpCallMatches) {
        coupling[service].directCalls.push(...httpCallMatches);
      }

      // Look for Kafka event usage
      const eventMatches = content.match(/EVENT_TOPICS\.\w+/g);
      if (eventMatches) {
        coupling[service].eventDependencies.push(...eventMatches);
      }
    }
  });
}

analyzeCoupling();
```

#### B∆∞·ªõc 3: Event Schema Validation Test

```javascript
// test-event-schemas.js
const Joi = require('joi');
const { EVENT_TOPICS } = require('./shared/event-types');

// Define expected schemas for each event type
const eventSchemas = {
  [EVENT_TOPICS.USER_CREATED]: Joi.object({
    userId: Joi.number().required(),
    username: Joi.string().required(),
    userEmail: Joi.string().email().required(),
    timestamp: Joi.string().isoDate().required()
  }),

  [EVENT_TOPICS.REGISTRATION_CREATED]: Joi.object({
    userId: Joi.number().required(),
    eventId: Joi.string().uuid().required(),
    userEmail: Joi.string().email().required(),
    timestamp: Joi.string().isoDate().required()
  }),

  [EVENT_TOPICS.NOTIFICATION_SENT]: Joi.object({
    userId: Joi.number().required(),
    eventId: Joi.string().uuid().required(),
    recipientEmail: Joi.string().email().required(),
    subject: Joi.string().required(),
    timestamp: Joi.string().isoDate().required()
  })
};

function validateEventSchemas() {
  console.log('Validating Event Schemas...');

  // Sample events to validate
  const sampleEvents = {
    [EVENT_TOPICS.USER_CREATED]: {
      userId: 123,
      username: 'testuser',
      userEmail: 'test@example.com',
      timestamp: '2024-03-15T10:30:00Z'
    },

    [EVENT_TOPICS.REGISTRATION_CREATED]: {
      userId: 123,
      eventId: '123e4567-e89b-12d3-a456-426614174000',
      userEmail: 'test@example.com',
      timestamp: '2024-03-15T10:30:00Z'
    },

    [EVENT_TOPICS.NOTIFICATION_SENT]: {
      userId: 123,
      eventId: '123e4567-e89b-12d3-a456-426614174000',
      recipientEmail: 'test@example.com',
      subject: 'Event Registration Confirmation',
      timestamp: '2024-03-15T10:30:00Z'
    }
  };

  let validSchemas = 0;
  let totalSchemas = Object.keys(eventSchemas).length;

  Object.entries(eventSchemas).forEach(([eventType, schema]) => {
    const sampleData = sampleEvents[eventType];

    const { error } = schema.validate(sampleData);
    if (error) {
      console.log(`‚ùå ${eventType}: ${error.message}`);
    } else {
      console.log(`‚úÖ ${eventType}: Schema valid`);
      validSchemas++;
    }
  });

  console.log(`\nSchema Validation Results:`);
  console.log(`Valid schemas: ${validSchemas}/${totalSchemas}`);
  console.log(`Schema compliance: ${(validSchemas/totalSchemas*100).toFixed(1)}%`);
}

validateEventSchemas();
```

---

## Metrics v√† KPIs ƒë·ªÉ ƒê√°nh Gi√°

### Scalability Metrics

- **Throughput**: > 1000 events/second
- **Response Time**: P95 < 200ms
- **Resource Utilization**: CPU < 70%, Memory < 80%
- **Horizontal Scale Factor**: C√≥ th·ªÉ scale 5x m√† kh√¥ng degradation

### Reliability Metrics

- **Message Delivery**: 99.9% success rate
- **System Uptime**: > 99.5%
- **Error Rate**: < 0.1%
- **Recovery Time**: < 30 seconds sau khi service restart

### Maintainability Metrics

- **Code Complexity**: Cyclomatic complexity < 10
- **Coupling Ratio**: < 20% direct calls, > 80% event-driven
- **Documentation Coverage**: > 90%
- **Test Coverage**: > 80%

---

## K·∫øt Lu·∫≠n

Event-Driven Architecture trong d·ª± √°n n√†y t·ªëi ∆∞u h√≥a cho:

1. **Scalability**: Kafka partitioning + microservice independence
2. **Reliability**: Message persistence + fault isolation + audit logging
3. **Maintainability**: Loose coupling + clear event contracts + service independence

C√°c c√¥ng c·ª• testing ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ƒë·∫£m b·∫£o nh·ªØng ƒë·∫∑c t√≠nh n√†y ƒë∆∞·ª£c duy tr√¨ qua c√°c chu k·ª≥ ph√°t tri·ªÉn v√† deployment.
